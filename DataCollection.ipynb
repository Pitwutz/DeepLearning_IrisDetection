{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Detection - Data Collection\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to complete:\n",
    "\n",
    "1. Take Pictures\n",
    "2. Partition Data\n",
    "3. Annotate Labels\n",
    "4. Data Augmentation (just training data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Dependencies installed\n",
    "\n",
    "- labelme\n",
    "- opencv-python\n",
    "- matplotlib\n",
    "- albumentations\n",
    "- notebook (for juypter notebook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Take Pictures\n",
    "\n",
    "Selfies in different positions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Partition Data\n",
    "\n",
    "Create random train, val and test data set (Proportions: 50:25:25).\n",
    "\n",
    "Move Images from data folder to their corresponding new folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folder paths\n",
    "source_folder = \"data/images\"\n",
    "train_folder = \"data/train/images\"\n",
    "val_folder = \"data/val/images\"\n",
    "test_folder = \"data/test/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create destination folders if dont exist already\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(val_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all available images\n",
    "image_files = os.listdir(source_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle images randomly\n",
    "random.shuffle(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of images per set\n",
    "total_images = len(image_files)\n",
    "train_size = int(0.5 * total_images)\n",
    "val_size = int(0.25 * total_images)\n",
    "test_size = total_images - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 51, 25, 27)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check sizes\n",
    "total_images, train_size, val_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move images to train folder\n",
    "for image_file in image_files[:train_size]:\n",
    "    shutil.copy(\n",
    "        os.path.join(source_folder, image_file), os.path.join(\n",
    "            train_folder, image_file)\n",
    "    )\n",
    "\n",
    "# Move images to val folder\n",
    "for image_file in image_files[train_size: train_size + val_size]:\n",
    "    shutil.copy(\n",
    "        os.path.join(source_folder, image_file), os.path.join(\n",
    "            val_folder, image_file)\n",
    "    )\n",
    "\n",
    "# Move images to test folder\n",
    "for image_file in image_files[train_size + val_size:]:\n",
    "    shutil.copy(\n",
    "        os.path.join(source_folder, image_file), os.path.join(\n",
    "            test_folder, image_file)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Label Data with Labelme\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data augmentation library\n",
    "import albumentations as alb\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use different augmentation operations to create a big training data set.\n",
    "\n",
    "- Randomly cropping input images to specified shape\n",
    "- Flipping input images horizontally with probability of 0.5\n",
    "- Randomly adjusting brightness & contrast of input images with probability of 0.2\n",
    "- Randomly adjusting gamma (also brightness but different operation) of the imput images with probability of 0.2\n",
    "- Randomly shifting rgb values of input images with probability of 0.2\n",
    "- Flipping input images vertically with probability of 0.5\n",
    "- Taking into the original label position into consideration while augmenting (label augmentation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_in_pixels = 460\n",
    "augmentor = alb.Compose(\n",
    "    [\n",
    "        alb.RandomCrop(width=size_in_pixels, height=size_in_pixels),\n",
    "        alb.HorizontalFlip(p=0.5),\n",
    "        alb.RandomBrightnessContrast(p=0.4),\n",
    "        alb.RandomGamma(p=0.4),\n",
    "        alb.RGBShift(p=0.4),\n",
    "        alb.VerticalFlip(p=0.5),\n",
    "    ],\n",
    "    keypoint_params=alb.KeypointParams(\n",
    "        format=\"xy\", label_fields=[\"class_labels\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # iterate over all images in train set\n",
    "# for image in os.listdir(os.path.join('data', 'train', 'images')):\n",
    "#     # i += 1 # remove later\n",
    "#     # opens image as array\n",
    "#     img = cv2.imread(os.path.join('data', 'train', 'images', image))\n",
    "\n",
    "#     # initiate classes (eyes visible or not, left and right)\n",
    "#     classes = [0, 0]\n",
    "\n",
    "#     # initiate coordiates of eyes if visible if not 0 (x-left, y-left, x-right, y-right)\n",
    "#     coords = [0, 0, 0, 0]\n",
    "\n",
    "#     # get corresponding label to current image (they have same file name)\n",
    "#     label_path = os.path.join('data', 'train', 'labels', f'{image.split(\".\")[0]}.json')\n",
    "\n",
    "#     # if label for image exists (if eyes are open or visible), update clases and coords\n",
    "#     if os.path.exists(label_path):\n",
    "#         with open(label_path, 'r') as f:\n",
    "#             label = json.load(f)\n",
    "\n",
    "#         # if we have just 1 label, we need to check which eye was labeled (one eye closed)\n",
    "#         if len(label['shapes']) == 1:\n",
    "#             if label['shapes'][0]['label'] == 'LeftEye':\n",
    "#                 classes[0] = 1\n",
    "#                 coords[0] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "#                 coords[1] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "#             # if not left eye its the right eye\n",
    "#             else:\n",
    "#                 classes[1] = 1\n",
    "#                 coords[2] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "#                 coords[3] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "\n",
    "#         # if both eyes are labeled, we need to check which eye was labeled 1st or 2nd\n",
    "#         if len(label['shapes']) == 2:\n",
    "#             # check first if we labeled the left eye first or second and update coords/classes\n",
    "#             if label['shapes'][0]['label'] =='LeftEye':\n",
    "#                 classes[0] = 1\n",
    "#                 coords[0] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "#                 coords[1] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "#             else:\n",
    "#                 classes[0] = 1\n",
    "#                 coords[0] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "#                 coords[1] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "\n",
    "#             # then check if we labeled the right eye first or second and update coords/classes\n",
    "#             if label['shapes'][0]['label'] =='RightEye':\n",
    "#                 classes[1] = 1\n",
    "#                 coords[2] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "#                 coords[3] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "#             else:\n",
    "#                 classes[1] = 1\n",
    "#                 coords[2] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "#                 coords[3] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "\n",
    "\n",
    "#     # now apply the augmentation to the image\n",
    "#     try:\n",
    "#         # 30 augementations generated for each image\n",
    "#         for x in range(30):\n",
    "#             # set keypoints of eyes to include them in the augmentation process\n",
    "#             keypoints = [(coords[:2]), (coords[2:])]\n",
    "#             # perform augmentation\n",
    "#             augmented = augmentor(image=img, keypoints=keypoints, class_labels=['LeftEye', 'RightEye'])\n",
    "#             # save augmentated image with slightly different name\n",
    "#             cv2.imwrite(os.path.join('data', 'train_aug', 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "#             # initiate annotations for augmentated data\n",
    "#             annotation = {}\n",
    "#             annotation['image'] = image\n",
    "#             annotation['class'] = [0,0]\n",
    "#             annotation['keypoints'] = [0,0,0,0]\n",
    "\n",
    "#             # if label for image exists we change to the augmentated keypoints and classes\n",
    "#             if os.path.exists(label_path):\n",
    "#                 if len(augmented['keypoints']) > 0:\n",
    "#                     for idx, cl in enumerate(augmented['class_labels']):\n",
    "#                         if cl == 'LeftEye':\n",
    "#                             annotation['class'][0] = 1\n",
    "#                             annotation['keypoints'][0] = augmented['keypoints'][idx][0]\n",
    "#                             annotation['keypoints'][1] = augmented['keypoints'][idx][1]\n",
    "#                         if cl == 'RightEye':\n",
    "#                             annotation['class'][1] = 1\n",
    "#                             annotation['keypoints'][2] = augmented['keypoints'][idx][0]\n",
    "#                             annotation['keypoints'][3] = augmented['keypoints'][idx][1]\n",
    "\n",
    "#             # save label of augmentated images\n",
    "#             with open(os.path.join('data', 'train_aug', 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "#                 json.dump(annotation, f)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def generate_augmented_pictures(data_category):\n",
    "    # iterate over all images in data set\n",
    "    for image in os.listdir(os.path.join(\"data\", data_category, \"images\")):\n",
    "        # i += 1 # remove later\n",
    "        data_base = os.path.join(\"data\", data_category)\n",
    "        aug_base = os.path.join(\"data\", f\"{data_category}_aug\")\n",
    "\n",
    "        # Ensure base directories for augmented images and labels exist\n",
    "        create_directory(os.path.join(aug_base, \"images\"))\n",
    "        create_directory(os.path.join(aug_base, \"labels\"))\n",
    "        # opens image as array\n",
    "        img = cv2.imread(os.path.join(\"data\", data_category, \"images\", image))\n",
    "\n",
    "        # initiate classes (eyes visible or not, left and right)\n",
    "        classes = [0, 0]\n",
    "\n",
    "        # initiate coordiates of eyes if visible if not 0 (x-left, y-left, x-right, y-right)\n",
    "        coords = [0, 0, 0, 0]\n",
    "\n",
    "        # get corresponding label to current image (they have same file name)\n",
    "        label_path = os.path.join(\n",
    "            \"data\", data_category, \"labels\", f'{image.split(\".\")[0]}.json'\n",
    "        )\n",
    "\n",
    "        # if label for image exists (if eyes are open or visible), update clases and coords\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, \"r\") as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            # if we have just 1 label, we need to check which eye was labeled (one eye closed)\n",
    "            if len(label[\"shapes\"]) == 1:\n",
    "                if label[\"shapes\"][0][\"label\"] == \"LeftEye\":\n",
    "                    classes[0] = 1\n",
    "                    coords[0] = np.squeeze(label[\"shapes\"][0][\"points\"])[0]\n",
    "                    coords[1] = np.squeeze(label[\"shapes\"][0][\"points\"])[1]\n",
    "                # if not left eye its the right eye\n",
    "                else:\n",
    "                    classes[1] = 1\n",
    "                    coords[2] = np.squeeze(label[\"shapes\"][0][\"points\"])[0]\n",
    "                    coords[3] = np.squeeze(label[\"shapes\"][0][\"points\"])[1]\n",
    "\n",
    "            # if both eyes are labeled, we need to check which eye was labeled 1st or 2nd\n",
    "            if len(label[\"shapes\"]) == 2:\n",
    "                # check first if we labeled the left eye first or second and update coords/classes\n",
    "                if label[\"shapes\"][0][\"label\"] == \"LeftEye\":\n",
    "                    classes[0] = 1\n",
    "                    coords[0] = np.squeeze(label[\"shapes\"][0][\"points\"])[0]\n",
    "                    coords[1] = np.squeeze(label[\"shapes\"][0][\"points\"])[1]\n",
    "                else:\n",
    "                    classes[0] = 1\n",
    "                    coords[0] = np.squeeze(label[\"shapes\"][1][\"points\"])[0]\n",
    "                    coords[1] = np.squeeze(label[\"shapes\"][1][\"points\"])[1]\n",
    "\n",
    "                # then check if we labeled the right eye first or second and update coords/classes\n",
    "                if label[\"shapes\"][0][\"label\"] == \"RightEye\":\n",
    "                    classes[1] = 1\n",
    "                    coords[2] = np.squeeze(label[\"shapes\"][0][\"points\"])[0]\n",
    "                    coords[3] = np.squeeze(label[\"shapes\"][0][\"points\"])[1]\n",
    "                else:\n",
    "                    classes[1] = 1\n",
    "                    coords[2] = np.squeeze(label[\"shapes\"][1][\"points\"])[0]\n",
    "                    coords[3] = np.squeeze(label[\"shapes\"][1][\"points\"])[1]\n",
    "\n",
    "                # normalizing the data\n",
    "                imageHeight = label[\"imageHeight\"]\n",
    "                imageWidth = label[\"imageWidth\"]\n",
    "                np.divide(coords, [imageHeight, imageWidth,\n",
    "                          imageHeight, imageWidth])\n",
    "\n",
    "        # now apply the augmentation to the image\n",
    "        try:\n",
    "            # 60 augementations generated for each image\n",
    "            for x in range(60):\n",
    "                # set keypoints of eyes to include them in the augmentation process\n",
    "                keypoints = [(coords[:2]), (coords[2:])]\n",
    "                # perform augmentation\n",
    "                augmented = augmentor(\n",
    "                    image=img, keypoints=keypoints, class_labels=[\n",
    "                        \"LeftEye\", \"RightEye\"]\n",
    "                )\n",
    "                # save augmentated image with slightly different name\n",
    "                cv2.imwrite(\n",
    "                    os.path.join(\n",
    "                        \"data\",\n",
    "                        data_category + \"_aug\",\n",
    "                        \"images\",\n",
    "                        f'{image.split(\".\")[0]}.{x}.jpg',\n",
    "                    ),\n",
    "                    augmented[\"image\"],\n",
    "                )\n",
    "\n",
    "                # initiate annotations for augmentated data\n",
    "                annotation = {}\n",
    "                annotation[\"image\"] = image\n",
    "                annotation[\"class\"] = [0, 0]\n",
    "                annotation[\"keypoints\"] = [0, 0, 0, 0]\n",
    "\n",
    "                # if label for image exists we change to the augmentated keypoints and classes\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented[\"keypoints\"]) > 0:\n",
    "                        for idx, cl in enumerate(augmented[\"class_labels\"]):\n",
    "                            if cl == \"LeftEye\":\n",
    "                                annotation[\"class\"][0] = 1\n",
    "                                annotation[\"keypoints\"][0] = augmented[\"keypoints\"][\n",
    "                                    idx\n",
    "                                ][0]\n",
    "                                annotation[\"keypoints\"][1] = augmented[\"keypoints\"][\n",
    "                                    idx\n",
    "                                ][1]\n",
    "                            if cl == \"RightEye\":\n",
    "                                annotation[\"class\"][1] = 1\n",
    "                                annotation[\"keypoints\"][2] = augmented[\"keypoints\"][\n",
    "                                    idx\n",
    "                                ][0]\n",
    "                                annotation[\"keypoints\"][3] = augmented[\"keypoints\"][\n",
    "                                    idx\n",
    "                                ][1]\n",
    "\n",
    "                annotation[\"keypoints\"] = list(\n",
    "                    np.divide(annotation[\"keypoints\"], [size_in_pixels] * 4)\n",
    "                )\n",
    "                # save label of augmentated images\n",
    "                with open(\n",
    "                    os.path.join(\n",
    "                        \"data\",\n",
    "                        data_category + \"_aug\",\n",
    "                        \"labels\",\n",
    "                        f'{image.split(\".\")[0]}.{x}.json',\n",
    "                    ),\n",
    "                    \"w\",\n",
    "                ) as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_augmented_pictures(\"train\")\n",
    "generate_augmented_pictures(\"val\")\n",
    "generate_augmented_pictures(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
